#!/usr/bin/env babel-node
/* eslint no-console: 0 */

import chalk from 'chalk'
import fs from 'fs-extra'

import handler from '../src/lib/handler'

const updateTest = (id, qty = 5, debug = false) => {
  if (!id) {
    console.log('Usage: npm run test:update {id} {pages}')
    return
  }
  if (!handler.scrapers[id]) {
    console.log(`Error: Invalid scraper ${chalk.white.bgRed.bold(id)}`)
    return
  }

  const allProducts = []
  const pages = []

  const scraper = handler.loadScraper(id)
  scraper.getAllProducts({ total: qty })

  console.log(`ðŸµ  Updating tests for ${chalk.green(id)}...`)

  scraper.emitter.on('gotProducts', ({ data, opts }) => {
    console.log(`${chalk.cyan(id)}: getting page `
      + `${chalk.green(opts.i + 1)} of ${chalk.green(opts.total)}`)

    const { products, nav, res, body } = data
    const path = res.request.path
    const url = handler.scrapers[id].HOST + path
    const file = `page-${opts.i}.html`
    allProducts.push({
      url,
      file: `${id}/${file}`,
      payload: { products, nav },
      res: { request: { path } },
    })
    pages.push({ file, body })
  })

  scraper.emitter.on('done', () => {
    if (!debug) {
      pages.forEach(page => {
        fs.outputFile(`./test/pages/${id}/${page.file}`, page.body, err => {
          if (err) console.log(err)
        })
      })
      fs.writeJson(`./test/data/${id}.json`, allProducts, err => {
        if (err) console.log(err)
      })
    }

    if (allProducts.length && pages.length) {
      console.log(`ðŸ‘  Test data updated for ${chalk.green(id)}: ${chalk.cyan(qty)} pages`)
      return
    }
  })

  scraper.emitter.on('error', err => {
    console.log(`ðŸ™ˆ  Couldn't update test for "${chalk.cyan(id)}"`)
    console.log(err)
  })
}

// updateTest(websiteId, qty, debug)
const websites = process.argv[2].split(',') || [process.argv[2]]
websites.map(website => updateTest(website, process.argv[3], process.argv[4]))
